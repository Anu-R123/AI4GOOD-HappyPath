{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/natal1e14/AI4GoodTeam2/blob/main/Densenet_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "attached-migration"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Densenet\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**Dense Convolutional Network (DenseNet), connects each layer to every other layer in a feed-forward fashion.**\n",
        "\n",
        "_ | _\n",
        "- | -\n",
        "![alt](https://pytorch.org/assets/images/densenet1.png) | ![alt](https://pytorch.org/assets/images/densenet2.png)"
      ],
      "id": "attached-migration"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-24fiYoXZDc0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, root_dir, captions_file,\n",
        "                 transform=transforms.Compose([]),\n",
        "                 freq_threshold=5):\n",
        "\n",
        "        self.root_dir = root_dir\n",
        "        self.df = pd.read_csv(root_dir + \"/\" + captions_file)\n",
        "        self.transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ])\n",
        "\n",
        "        self.imgs = self.df[\"image_name\"]\n",
        "        self.captions = self.df[\"label\"]\n",
        "        self.bad = 0\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        caption = self.captions[idx]\n",
        "        # if caption.lower()==\"positive\":\n",
        "        #   caption = 0\n",
        "        # elif caption.lower()==\"negative\":\n",
        "        #   caption = 1\n",
        "        # else:\n",
        "        #   caption = 2\n",
        "\n",
        "        img_name = self.imgs[idx]\n",
        "        try:\n",
        "          img_location = os.path.join(self.root_dir + '/images', img_name + \".jpg\")\n",
        "          img = Image.open(img_location).convert(\"RGB\")\n",
        "        except:\n",
        "          try: \n",
        "            img_location = os.path.join(self.root_dir + '/photo', img_name + \".jpg\")\n",
        "            img = Image.open(img_location).convert(\"RGB\")\n",
        "          except: \n",
        "            img_location = os.path.join(self.root_dir + '/photo', \"694551465.jpg\")\n",
        "            img = Image.open(img_location).convert(\"RGB\")\n",
        "            self.bad += 1\n",
        "\n",
        "\n",
        "        # apply the transfromation to the image\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        #returns image at index idx + corresponding caption\n",
        "        return img, caption\n"
      ],
      "id": "-24fiYoXZDc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTtXVZLiIPBE"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import densenet121, DenseNet\n",
        "import torch \n",
        "from typing import Tuple\n",
        "\n",
        "class SentimentDenseNet(DenseNet):\n",
        "\n",
        "\n",
        "  def __init__(self): \n",
        "               \n",
        "        #        , growth_rate: int = 32,\n",
        "        # block_config: Tuple[int, int, int, int] = (6, 12, 24, 16),\n",
        "        # num_init_features: int = 64,\n",
        "        # bn_size: int = 4,\n",
        "        # drop_rate: float = 0,\n",
        "        # num_classes: int = 1000,\n",
        "        # memory_efficient: bool = False):\n",
        "    \n",
        "    #super().__init__()\n",
        "    #super(densenet121, self).__init__(pretrained=True, progress=True)\n",
        "    # super(DenseNet, self).__init__(growth_rate=32, block_config=(6, 12, 24, 16), \n",
        "    #                                num_init_features=64, \n",
        "    #                                pretrained=True, \n",
        "    #                                progress=True)\n",
        "\n",
        "\n",
        "    keys = ['norm1', 'relu1', 'conv1', 'norm2', 're']\n",
        "\n",
        "    super(DenseNet, self).__init__()\n",
        "    self.model = densenet121(pretrained=True, progress=True)\n",
        "    #Freeze Block 1 and Block 2\n",
        "    block1 = self.model.features[4]\n",
        "    for i in range(1,7):\n",
        "      block1['denselayer' + str(i)].requires_grad= False\n",
        "\n",
        "    block2 = self.model.features[6]\n",
        "    for i in range(1,13):\n",
        "      block2['denselayer' + str(i)].requires_grad= False\n",
        "        # self.model.features[4].requires_grad = False\n",
        "    # self.model.features[6].requires_grad = False\n",
        "\n",
        "    # #Unfreeze Block 3 and Block 4\n",
        "\n",
        "    block3 = self.model.features[8]\n",
        "    for i in range(1, 25):\n",
        "      block3['denselayer' + str(i)].requires_grad= True\n",
        "\n",
        "    block4 = self.model.features[10]\n",
        "    for i in range(1,17):\n",
        "      block4['denselayer' + str(i)].requires_grad= True\n",
        "    \n",
        "    # self.model.features[8].requires_grad = True\n",
        "    # self.model.features[10].requires_grad = True\n",
        "   # print(self.model.features[4:11])\n",
        "\n",
        "    self.globalAvg = torch.nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "   # (65536x1 and 64x512)\n",
        "    self.dense = _DenseLayer(512,3,4,0)#torch.nn.Linear(in_features= 512, out_features=3)\n",
        "\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "    batch_size = x.shape[0]    #batch_size x (2d image size) x 3 colour channels\n",
        "    #print(x.shape) # torch.Size([8, 3, 224, 224])\n",
        "    out = self.model.features(x) \n",
        "    #print(out.shape) #torch.Size([8, 1024, 7, 7]) #Correct -- output of last Dense layer is 7x7\n",
        "    out = self.globalAvg(out)\n",
        "    #print(out.shape) #torch.Size([8, 1024, 1, 1])\n",
        "    out = self.dropout(out)\n",
        "    #print(out.shape) #torch.Size([8, 1024, 1, 1])\n",
        "    out = out.view(batch_size, 512, -1) #torch.Size([8, 2, 512])\n",
        "    #print(out.shape)\n",
        "    out = self.dense(out.unsqueeze(-1)) #Where to do regularization???\n",
        "    #print(out.shape)\n",
        "    out = out.squeeze()\n",
        "    out = out.view(batch_size, -1, 1)\n",
        "\n",
        "    out = torch.nn.functional.softmax(out[:,0,:])  #8 x 2 x 3\n",
        "    #print(out.shape) # should be 8x3... but out_features from dense is 512...\n",
        "    return out \n",
        "\n",
        "   \n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "OTtXVZLiIPBE"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class _DenseLayer(torch.nn.Module):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate, memory_efficient=False):\n",
        "        super(_DenseLayer, self).__init__()\n",
        "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
        "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)),\n",
        "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
        "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
        "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)),\n",
        "        self.drop_rate = float(drop_rate)\n",
        "        self.memory_efficient = memory_efficient\n",
        "\n",
        "    def bn_function(self, inputs):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        out = self.norm1(concated_features)\n",
        "        out = self.relu1(out)\n",
        "        bottleneck_output = self.conv1(out)  # noqa: T484\n",
        "        return bottleneck_output\n",
        "\n",
        "    # todo: rewrite when torchscript supports any\n",
        "    def any_requires_grad(self, input):\n",
        "        # type: (List[Tensor]) -> bool\n",
        "        for tensor in input:\n",
        "            if tensor.requires_grad:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    @torch.jit.unused  # noqa: T484\n",
        "    def call_checkpoint_bottleneck(self, input):\n",
        "        # type: (List[Tensor]) -> Tensor\n",
        "        def closure(*inputs):\n",
        "            return self.bn_function(inputs)\n",
        "\n",
        "        return cp.checkpoint(closure, *input)\n",
        "\n",
        "    # @torch.jit._overload_method  # noqa: F811\n",
        "    # def forward(self, input):\n",
        "    #     # type: (List[Tensor]) -> (Tensor)\n",
        "    #     pass\n",
        "\n",
        "    # @torch.jit._overload_method  # noqa: F811\n",
        "    # def forward(self, input):\n",
        "    #     # type: (Tensor) -> (Tensor)\n",
        "    #     pass\n",
        "\n",
        "    # torchscript does not yet support *args, so we overload method\n",
        "    # allowing it to take either a List[Tensor] or single Tensor\n",
        "    def forward(self, input):  # noqa: F811\n",
        "        if isinstance(input, Tensor):\n",
        "            prev_features = [input]\n",
        "        else:\n",
        "            prev_features = input\n",
        "\n",
        "        if self.memory_efficient and self.any_requires_grad(prev_features):\n",
        "            if torch.jit.is_scripting():\n",
        "                raise Exception(\"Memory Efficient not supported in JIT\")\n",
        "\n",
        "            bottleneck_output = self.call_checkpoint_bottleneck(prev_features)\n",
        "        else:\n",
        "            bottleneck_output = self.bn_function(prev_features)\n",
        "\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return new_features"
      ],
      "metadata": {
        "id": "3--QaC6DuRrY"
      },
      "id": "3--QaC6DuRrY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fycMsVGLerBp"
      },
      "outputs": [],
      "source": [
        "model = SentimentDenseNet()\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/ai4good/trained'))\n",
        "\n",
        "train_data = SentimentDataset('/content/drive/MyDrive/ai4good', 'train.csv')\n",
        "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "\n",
        "valid_data = SentimentDataset('/content/drive/MyDrive/ai4good', 'valid.csv')\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=8, shuffle=True)\n",
        "\n",
        "lr=0.05\n",
        "weight_decay=0.01\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "train_error_rates = []\n",
        "test_error_rates = []\n",
        "import numpy as np\n",
        "\n",
        "use_gpu = True\n",
        "\n",
        "from tqdm import tqdm \n",
        "\n",
        "if use_gpu:\n",
        "  # switch model to GPU\n",
        "  model.cuda()\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "from functools import partial\n",
        "tqdm = partial(tqdm, position=0, leave=True)\n",
        "\n",
        "val_acc = []\n",
        "train_acc =[]\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "  train_loss = 0 \n",
        "  n_iter = 0 \n",
        "  total = 0\n",
        "  correct = 0\n",
        "  model.train()\n",
        "  for i, (images, labels) in enumerate(tqdm(train_dataloader)): \n",
        "    optimizer.zero_grad() \n",
        "    \n",
        "    if use_gpu: \n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images).squeeze()\n",
        "   # print(outputs.shape)\n",
        "    \n",
        "    # to compute the train_error_rates  \n",
        "    predictions = 1* (outputs >= 0.5) #torch.max(outputs, 1)\n",
        "    correct += torch.sum(labels == predictions).item()\n",
        "    total += labels.shape[0]\n",
        "\n",
        "    # print(outputs)\n",
        "    # print(labels)\n",
        "    \n",
        "    # compute loss \n",
        "   # print(type(predictions)\n",
        "    loss_bs = criterion(outputs, labels.float())\n",
        "    # compute gradients\n",
        "    loss_bs.backward()\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss_bs.detach().item()\n",
        "\n",
        "    n_iter += 1\n",
        "    del images, labels\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  train_error_rate = 1 - correct/total\n",
        "  train_acc.append(correct/total)\n",
        "  #print(train_data.bad)\n",
        "\n",
        "\n",
        "  #torch.no_grad()\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  test_accuracy = 0\n",
        "  total_test = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(tqdm(valid_dataloader)): \n",
        "\n",
        "      if use_gpu: \n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "\n",
        "      outputs = model(images).squeeze()\n",
        "      #print(outputs)\n",
        "      #print(labels)\n",
        "      \n",
        "      # to compute the train_error_rates  \n",
        "      predictions = (outputs >= 0.5) #torch.max(outputs, 1)\n",
        "      test_accuracy += torch.sum(labels == predictions).item()\n",
        "      total_test += labels.shape[0]\n",
        "      test_loss += criterion(outputs, labels.float())\n",
        "\n",
        "      del images, labels\n",
        "      torch.cuda.empty_cache()\n",
        "    \n",
        "    \n",
        "\n",
        "  # with torch.no_grad():\n",
        "  #   test_loss, test_error_rate = prediction(test_loader, model)\n",
        "\n",
        "  train_error_rates.append(train_error_rate)\n",
        "  test_error_rates.append(1- test_accuracy/total_test)\n",
        "  train_losses.append(train_loss/n_iter)\n",
        "  test_losses.append(test_loss)\n",
        "  val_acc.append(test_accuracy/total_test)\n",
        "  \n",
        "  print('Epoch: {}/{}, Loss: {:.4f}, Val Accuracy: {:.4f}, train Acc: {:.4f}'.format(epoch+1, num_epochs, train_loss/n_iter, test_accuracy/total_test, correct/total))"
      ],
      "id": "fycMsVGLerBp"
    },
    {
      "cell_type": "code",
      "source": [
        " correct = 0\n",
        " total_test=0\n",
        " with torch.no_grad():\n",
        "    for i, (images, labels) in enumerate(tqdm(valid_dataloader)): \n",
        "\n",
        "      if use_gpu: \n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "\n",
        "      outputs = model(images)\n",
        "      \n",
        "      # to compute the train_error_rates  \n",
        "      _, predictions = torch.max(outputs, 1)\n",
        "      correct += torch.sum(labels == predictions).item()\n",
        "      total_test += labels.shape[0]\n",
        "      test_loss += criterion(outputs, labels)\n",
        "\n",
        "      del images, labels\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "print(correct/total_test)\n",
        "    "
      ],
      "metadata": {
        "id": "mOykt2BmRfVo"
      },
      "id": "mOykt2BmRfVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/ai4good/trained')"
      ],
      "metadata": {
        "id": "ru1kB50VSUw_"
      },
      "id": "ru1kB50VSUw_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "3nOwWqZMT2wj"
      },
      "id": "3nOwWqZMT2wj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "JI0dMpJXslQ1"
      },
      "id": "JI0dMpJXslQ1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReQelYIrlSS2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/MyDrive/ai4good/merged.csv')\n",
        "data = data[~data['image_name'].isin(bad)]\n",
        "\n",
        "data['label'] = data['label'].replace('Positive',0)\n",
        "data['label'] = data['label'].replace('Negative',1)\n",
        "data['label'] = data['label'].replace('Neutral',2)\n",
        "data['label'] = data['label'].replace('positive',0)\n",
        "data['label'] = data['label'].replace('negative',1)\n",
        "data['label'] = data['label'].replace('neutral',2)\n",
        "print(data.head())\n",
        "print(data['label'].dtypes)\n",
        "print(len(data['label'==0]))\n",
        "print(len(data['label'==1]))\n",
        "print(len(data['label'==2]))\n",
        "\n",
        "\n"
      ],
      "id": "ReQelYIrlSS2"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(data[\"image_name\"], data[\"label\"], test_size=0.2, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ecH5Ys5TS9GJ"
      },
      "id": "ecH5Ys5TS9GJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "29eb6kUDRyjM"
      },
      "id": "29eb6kUDRyjM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzCBNnsomb1F"
      },
      "outputs": [],
      "source": [
        "train_rows = pd.merge(X_train, y_train, right_index=True, left_index=True)\n",
        "valid_rows =pd.merge(X_val, y_val, right_index=True, left_index=True)\n",
        "\n",
        "train_rows.to_csv('/content/drive/MyDrive/ai4good/train.csv')\n",
        "valid_rows.to_csv('/content/drive/MyDrive/ai4good/valid.csv')"
      ],
      "id": "OzCBNnsomb1F"
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('unsuccessful_photos_ids.txt')\n",
        "\n",
        "bad = []\n",
        "\n",
        "for line in f.readlines():\n",
        "  line = line.split(\"\\n\")\n",
        "  bad.append(line[0])\n",
        "\n",
        "f.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "i3cRkbCXwJ3U"
      },
      "id": "i3cRkbCXwJ3U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bad[800])"
      ],
      "metadata": {
        "id": "1Grwaym0wcge"
      },
      "id": "1Grwaym0wcge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].value_counts()"
      ],
      "metadata": {
        "id": "Yxt0MmBAw1xO"
      },
      "id": "Yxt0MmBAw1xO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos =  data[data['label']==0]\n",
        "rest = data[data['label'] ==1]\n",
        "pos = pos.head(5000)\n",
        "\n",
        "data = rest.append(pos)\n",
        "data['label'].value_counts()"
      ],
      "metadata": {
        "id": "7pvwqriUShAv"
      },
      "id": "7pvwqriUShAv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC4cpmF1gzFg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "PC4cpmF1gzFg"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Densenet model.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}